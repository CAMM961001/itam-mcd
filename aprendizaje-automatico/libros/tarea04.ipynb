{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4949a8b-263a-42d5-aa13-b85602e1f8d9",
   "metadata": {},
   "source": [
    "# Regularización y variabilidad\n",
    "\n",
    "Esta es la solución a la tarea 4 referente a la [sección 5](https://felipegonzalez.github.io/aprendizaje-maquina-mcd-2022/05-regularizacion-1.html) de la notas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3386aac-1338-491a-94af-df086a669418",
   "metadata": {},
   "source": [
    "En este ejemplo hacemos **análisis de sentimiento**, intentanto predecir si reseñas de películas son positivas o negativas a partir del texto de las reseñas. En este ejemplo veremos un enfoque relativamente simple, que consiste en considerar solamente las palabras que contienen las reseñas, sin tomar en cuenta el orden (el modelo de bolsa de palabras o **bag of words**).\n",
    "\n",
    "Usaremos regresión lineal, aunque este tipo de problema es mejor resolverlo usando algún método para variables binarias o categóricas (regresión logística por ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a73bdfa-01eb-4f79-9c9d-04c6e2c79134",
   "metadata": {},
   "source": [
    "## Feature Engineering Básico\n",
    "\n",
    "Hay muchas maneras de preprocesar los datos para obtener variables numéricas a partir del texto. En este caso simplemente tomamos las palabras que ocurren más frecuentemente. \n",
    "* Encontramos las 3000 palabras más frecuentes sobre todos los textos, por ejemplo. Estas palabras son nuestro **vocabulario**.\n",
    "* Registramos en qué documentos ocurre cada una de esas palabras.\n",
    "* Cada palabra es una columna de nuestros datos, el valor es 1 si la palabra ocurre en documento y 0 si no ocurre.\n",
    "\n",
    "\n",
    "Por ejemplo, para el texto \"Un gato blanco, un gato negro\", \"un perro juega\", \"un astronauta juega\" quedarían los datos:\n",
    "|texto_id | un | gato | negro | blanco | perro | juega |\n",
    "-----|------|-------|--------|-------|-------  | ---- |\n",
    "| texto_1 | 1  |  1   |   1   |   1    |  0    | 0     |\n",
    "| texto_2 | 1  |  0   |  0    | 0      |  1    |  1  |\n",
    "| texto_3 | 1  |  0   |  0    | 0      |  0    |  1   |\n",
    "\n",
    "Nótese que la palabra **astronauta** no está en nuestro vocabulario para este ejemplo.\n",
    "\n",
    "Hay varias opciones para tener mejores variables, que pueden o no ayudar en este problema (no las exploramos en este ejercicio):\n",
    "* Usar conteos de frecuencias de ocurrencia de palabras en cada documento, o usar log(1+ conteo), en lugar de 0-1's\n",
    "* Usar palabras frecuentes, pero quitar las que son **stopwords**, como son preposiciones y artículos entre otras, pues no tienen significado: en inglés, por ejemplo, **so, is, then, the, a**, etc.\n",
    "* Lematizar palabras: por ejemplo, contar en la misma categoría **movie** y **movies**, o **funny** y **funniest**, etc.\n",
    "* Usar indicadores binarios si la palabra ocurre o no en lugar de la frecuencia\n",
    "* Usar frecuencias ponderadas por qué tan rara es una palabra sobre todos los documentos (frecuencia inversa sobre documentos)\n",
    "* Usar pares de palabras en lugar de palabras sueltas: por ejemplo: juntar \"not\" con la palabra que sigue (en lugar de usar **not** y **bad** por separado, juntar en una palabra **not_bad**),\n",
    "* Usar técnicas de reducción de dimensionalidad que considera la co-ocurrencia de palabras (veremos más adelante en el curso).\n",
    "* Muchas otras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab046079-caf1-403b-8dc5-1f109df87aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
